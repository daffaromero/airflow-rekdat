{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab9d8d3b-0eff-4719-8fd2-9349a9708ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\public\\miniconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\public\\miniconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\public\\miniconda3\\lib\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in c:\\users\\public\\miniconda3\\lib\\site-packages (from nltk) (4.63.0)\n",
      "Requirement already satisfied: click in c:\\users\\public\\miniconda3\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\public\\miniconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9156b271-8804-44ce-88ab-4f904939af87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\AULIA\n",
      "[nltk_data]     ASUSK401L\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\AULIA\n",
      "[nltk_data]     ASUSK401L\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\AULIA\n",
      "[nltk_data]     ASUSK401L\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\AULIA\n",
      "[nltk_data]     ASUSK401L\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be629b-ef74-4cac-91ed-11472151990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "sia = TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edb6687-f85f-446e-afac-2255d989541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggel_data = pd.read_csv('tweet_kaggle.csv')\n",
    "scrap_data = pd.read_csv('tweets_crawl_new.csv')\n",
    "data_file = kaggel_data.append(scrap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef0a8e0a-a92d-43ab-8a5e-3c5a77308f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitid</th>\n",
       "      <th>twitcontent</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467810369</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1467810672</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>scotthamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1467810917</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>mattycus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1467811184</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>ElleCTF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1467811193</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>Karoli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>1597688327142281216</td>\n",
       "      <td>@ChefTomKerridge commentating on the england w...</td>\n",
       "      <td>teejayflaherty1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>1597688326164992000</td>\n",
       "      <td>The Welsh passion, the pride, the fight, wow.....</td>\n",
       "      <td>KevRussell7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>1597688324634087425</td>\n",
       "      <td>It is incredible to see how #ai failing to pre...</td>\n",
       "      <td>Icocbekristos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>1597688322272509952</td>\n",
       "      <td>Im running out of superlatives for Ream as a C...</td>\n",
       "      <td>shaneevent11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>1597688320733036545</td>\n",
       "      <td>RT @ManUtd: A fantastic free kick from @Marcus...</td>\n",
       "      <td>bellajw_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2900 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   twitid                                        twitcontent  \\\n",
       "0              1467810369  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1              1467810672  is upset that he can't update his Facebook by ...   \n",
       "2              1467810917  @Kenichan I dived many times for the ball. Man...   \n",
       "3              1467811184    my whole body feels itchy and like its on fire    \n",
       "4              1467811193  @nationwideclass no, it's not behaving at all....   \n",
       "...                   ...                                                ...   \n",
       "1795  1597688327142281216  @ChefTomKerridge commentating on the england w...   \n",
       "1796  1597688326164992000  The Welsh passion, the pride, the fight, wow.....   \n",
       "1797  1597688324634087425  It is incredible to see how #ai failing to pre...   \n",
       "1798  1597688322272509952  Im running out of superlatives for Ream as a C...   \n",
       "1799  1597688320733036545  RT @ManUtd: A fantastic free kick from @Marcus...   \n",
       "\n",
       "             username  \n",
       "0     _TheSpecialOne_  \n",
       "1       scotthamilton  \n",
       "2            mattycus  \n",
       "3             ElleCTF  \n",
       "4              Karoli  \n",
       "...               ...  \n",
       "1795  teejayflaherty1  \n",
       "1796      KevRussell7  \n",
       "1797    Icocbekristos  \n",
       "1798     shaneevent11  \n",
       "1799         bellajw_  \n",
       "\n",
       "[2900 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4795ccf9-76c3-4fe5-8fd8-899896443c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = data_file.drop_duplicates('twitcontent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9237244-15a6-4bcb-a624-c13e6355ecaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2042 entries, 0 to 1798\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   twitid       2042 non-null   int64 \n",
      " 1   twitcontent  2042 non-null   object\n",
      " 2   username     2042 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 63.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data_file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3873bcc3-3455-4153-998e-4c0b877eed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff851e-7b3b-46be-83a1-91a55e030684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    \n",
    "    return text\n",
    "data_file['twitcontent'] = data_file['twitcontent'].apply(lambda x:clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e6a82-9583-42b6-afd9-7a353ecded1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "data_file['twitcontent']=data_file['twitcontent']\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "data_file['tokenized'] = data_file['twitcontent'].apply(lambda x: tokenization(x.lower()))\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text\n",
    "    \n",
    "data_file['No_stopwords'] = data_file['tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def stemming1(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "data_file['stemmed_porter'] = data_file['No_stopwords'].apply(lambda x: stemming1(x))\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "s_stemmer = SnowballStemmer(language='english')\n",
    "def stemming2(text):\n",
    "    text = [s_stemmer.stem(word) for word in text]\n",
    "    return text\n",
    "data_file['stemmed_snowball'] = data_file['No_stopwords'].apply(lambda x: stemming2(x))\n",
    "\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer(text):\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "    return text\n",
    "\n",
    "data_file['lemmatized'] = data_file['No_stopwords'].apply(lambda x: lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85f83541-1d42-4db4-94d4-09909e2329ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1027ee86-7385-4bc7-ab6f-f08e12d1e15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-01 00:27:01,177 loading file C:\\Users\\AULIA ASUSK401L\\.flair\\models\\sentiment-en-mix-distillbert_4.pt\n"
     ]
    }
   ],
   "source": [
    "sentiment_model = flair.models.TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c33a9181-dfe9-4d97-b8c6-1ca1cf2c2b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = []\n",
    "confidence = []\n",
    "\n",
    "for sentence in data_file['twitcontent']:\n",
    "    if sentence == \"\":\n",
    "        sentiment.append(\"\")\n",
    "        confidence.append(\"\")\n",
    "    \n",
    "    else:\n",
    "        sample = flair.data.Sentence(sentence)\n",
    "        sentiment_model.predict(sample)\n",
    "        \n",
    "        sentiment.append(sample.labels[0].value)\n",
    "        confidence.append(sample.labels[0].score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a318d-fa71-432b-a2fe-9de74ad54247",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file['sentiment'] = sentiment\n",
    "data_file['confidence'] = confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2240c802-2989-45a8-b6ff-db7d17b3bfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitid</th>\n",
       "      <th>twitcontent</th>\n",
       "      <th>username</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>No_stopwords</th>\n",
       "      <th>stemmed_porter</th>\n",
       "      <th>stemmed_snowball</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>sentiment_flair</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467810369</td>\n",
       "      <td>switchfoot httptwitpiccom2y1zl  awww thats a b...</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>[switchfoot, httptwitpiccom2y1zl, awww, thats,...</td>\n",
       "      <td>[switchfoot, httptwitpiccom2y1zl, awww, thats,...</td>\n",
       "      <td>[switchfoot, httptwitpiccom2y1zl, awww, that, ...</td>\n",
       "      <td>[switchfoot, httptwitpiccom2y1zl, awww, that, ...</td>\n",
       "      <td>[switchfoot, httptwitpiccom2y1zl, awww, thats,...</td>\n",
       "      <td>negative</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.996120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1467810672</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>[is, upset, that, he, cant, update, his, faceb...</td>\n",
       "      <td>[upset, cant, update, facebook, texting, might...</td>\n",
       "      <td>[upset, cant, updat, facebook, text, might, cr...</td>\n",
       "      <td>[upset, cant, updat, facebook, text, might, cr...</td>\n",
       "      <td>[upset, cant, update, facebook, texting, might...</td>\n",
       "      <td>negative</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.996055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1467810917</td>\n",
       "      <td>kenichan i dived many times for the ball manag...</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>[kenichan, i, dived, many, times, for, the, ba...</td>\n",
       "      <td>[kenichan, dived, many, times, ball, managed, ...</td>\n",
       "      <td>[kenichan, dive, mani, time, ball, manag, save...</td>\n",
       "      <td>[kenichan, dive, mani, time, ball, manag, save...</td>\n",
       "      <td>[kenichan, dived, many, time, ball, managed, s...</td>\n",
       "      <td>positive</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.854769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1467811184</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>[whole, body, feels, itchy, like, fire, ]</td>\n",
       "      <td>[whole, bodi, feel, itchi, like, fire, ]</td>\n",
       "      <td>[whole, bodi, feel, itchi, like, fire, ]</td>\n",
       "      <td>[whole, body, feel, itchy, like, fire, ]</td>\n",
       "      <td>negative</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.985915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1467811193</td>\n",
       "      <td>nationwideclass no its not behaving at all im ...</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>[nationwideclass, no, its, not, behaving, at, ...</td>\n",
       "      <td>[nationwideclass, behaving, im, mad, cant, see, ]</td>\n",
       "      <td>[nationwideclass, behav, im, mad, cant, see, ]</td>\n",
       "      <td>[nationwideclass, behav, im, mad, cant, see, ]</td>\n",
       "      <td>[nationwideclass, behaving, im, mad, cant, see, ]</td>\n",
       "      <td>negative</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>1597688328098557952</td>\n",
       "      <td>lets go usa worldcup</td>\n",
       "      <td>Void_Chasers</td>\n",
       "      <td>[lets, go, usa, worldcup, ]</td>\n",
       "      <td>[lets, go, usa, worldcup, ]</td>\n",
       "      <td>[let, go, usa, worldcup, ]</td>\n",
       "      <td>[let, go, usa, worldcup, ]</td>\n",
       "      <td>[let, go, usa, worldcup, ]</td>\n",
       "      <td>positive</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.978026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>1597688327142281216</td>\n",
       "      <td>cheftomkerridge commentating on the england wa...</td>\n",
       "      <td>teejayflaherty1</td>\n",
       "      <td>[cheftomkerridge, commentating, on, the, engla...</td>\n",
       "      <td>[cheftomkerridge, commentating, england, wales...</td>\n",
       "      <td>[cheftomkerridg, comment, england, wale, game,...</td>\n",
       "      <td>[cheftomkerridg, comment, england, wale, game,...</td>\n",
       "      <td>[cheftomkerridge, commentating, england, wale,...</td>\n",
       "      <td>positive</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.994031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>1597688326164992000</td>\n",
       "      <td>the welsh passion the pride the fight wowits a...</td>\n",
       "      <td>KevRussell7</td>\n",
       "      <td>[the, welsh, passion, the, pride, the, fight, ...</td>\n",
       "      <td>[welsh, passion, pride, fight, wowits, shame, ...</td>\n",
       "      <td>[welsh, passion, pride, fight, wowit, shame, t...</td>\n",
       "      <td>[welsh, passion, pride, fight, wowit, shame, t...</td>\n",
       "      <td>[welsh, passion, pride, fight, wowits, shame, ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.865182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>1597688324634087425</td>\n",
       "      <td>it is incredible to see how ai failing to pred...</td>\n",
       "      <td>Icocbekristos</td>\n",
       "      <td>[it, is, incredible, to, see, how, ai, failing...</td>\n",
       "      <td>[incredible, see, ai, failing, predict, worldc...</td>\n",
       "      <td>[incred, see, ai, fail, predict, worldcup, win...</td>\n",
       "      <td>[incred, see, ai, fail, predict, worldcup, win...</td>\n",
       "      <td>[incredible, see, ai, failing, predict, worldc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.884833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>1597688322272509952</td>\n",
       "      <td>im running out of superlatives for ream as a c...</td>\n",
       "      <td>shaneevent11</td>\n",
       "      <td>[im, running, out, of, superlatives, for, ream...</td>\n",
       "      <td>[im, running, superlatives, ream, cb, hes, pla...</td>\n",
       "      <td>[im, run, superl, ream, cb, he, play, like, be...</td>\n",
       "      <td>[im, run, superl, ream, cb, hes, play, like, b...</td>\n",
       "      <td>[im, running, superlative, ream, cb, he, playi...</td>\n",
       "      <td>negative</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.942696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2042 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   twitid                                        twitcontent  \\\n",
       "0              1467810369  switchfoot httptwitpiccom2y1zl  awww thats a b...   \n",
       "1              1467810672  is upset that he cant update his facebook by t...   \n",
       "2              1467810917  kenichan i dived many times for the ball manag...   \n",
       "3              1467811184    my whole body feels itchy and like its on fire    \n",
       "4              1467811193  nationwideclass no its not behaving at all im ...   \n",
       "...                   ...                                                ...   \n",
       "1794  1597688328098557952                              lets go usa worldcup    \n",
       "1795  1597688327142281216  cheftomkerridge commentating on the england wa...   \n",
       "1796  1597688326164992000  the welsh passion the pride the fight wowits a...   \n",
       "1797  1597688324634087425  it is incredible to see how ai failing to pred...   \n",
       "1798  1597688322272509952  im running out of superlatives for ream as a c...   \n",
       "\n",
       "             username                                          tokenized  \\\n",
       "0     _TheSpecialOne_  [switchfoot, httptwitpiccom2y1zl, awww, thats,...   \n",
       "1       scotthamilton  [is, upset, that, he, cant, update, his, faceb...   \n",
       "2            mattycus  [kenichan, i, dived, many, times, for, the, ba...   \n",
       "3             ElleCTF  [my, whole, body, feels, itchy, and, like, its...   \n",
       "4              Karoli  [nationwideclass, no, its, not, behaving, at, ...   \n",
       "...               ...                                                ...   \n",
       "1794     Void_Chasers                        [lets, go, usa, worldcup, ]   \n",
       "1795  teejayflaherty1  [cheftomkerridge, commentating, on, the, engla...   \n",
       "1796      KevRussell7  [the, welsh, passion, the, pride, the, fight, ...   \n",
       "1797    Icocbekristos  [it, is, incredible, to, see, how, ai, failing...   \n",
       "1798     shaneevent11  [im, running, out, of, superlatives, for, ream...   \n",
       "\n",
       "                                           No_stopwords  \\\n",
       "0     [switchfoot, httptwitpiccom2y1zl, awww, thats,...   \n",
       "1     [upset, cant, update, facebook, texting, might...   \n",
       "2     [kenichan, dived, many, times, ball, managed, ...   \n",
       "3             [whole, body, feels, itchy, like, fire, ]   \n",
       "4     [nationwideclass, behaving, im, mad, cant, see, ]   \n",
       "...                                                 ...   \n",
       "1794                        [lets, go, usa, worldcup, ]   \n",
       "1795  [cheftomkerridge, commentating, england, wales...   \n",
       "1796  [welsh, passion, pride, fight, wowits, shame, ...   \n",
       "1797  [incredible, see, ai, failing, predict, worldc...   \n",
       "1798  [im, running, superlatives, ream, cb, hes, pla...   \n",
       "\n",
       "                                         stemmed_porter  \\\n",
       "0     [switchfoot, httptwitpiccom2y1zl, awww, that, ...   \n",
       "1     [upset, cant, updat, facebook, text, might, cr...   \n",
       "2     [kenichan, dive, mani, time, ball, manag, save...   \n",
       "3              [whole, bodi, feel, itchi, like, fire, ]   \n",
       "4        [nationwideclass, behav, im, mad, cant, see, ]   \n",
       "...                                                 ...   \n",
       "1794                         [let, go, usa, worldcup, ]   \n",
       "1795  [cheftomkerridg, comment, england, wale, game,...   \n",
       "1796  [welsh, passion, pride, fight, wowit, shame, t...   \n",
       "1797  [incred, see, ai, fail, predict, worldcup, win...   \n",
       "1798  [im, run, superl, ream, cb, he, play, like, be...   \n",
       "\n",
       "                                       stemmed_snowball  \\\n",
       "0     [switchfoot, httptwitpiccom2y1zl, awww, that, ...   \n",
       "1     [upset, cant, updat, facebook, text, might, cr...   \n",
       "2     [kenichan, dive, mani, time, ball, manag, save...   \n",
       "3              [whole, bodi, feel, itchi, like, fire, ]   \n",
       "4        [nationwideclass, behav, im, mad, cant, see, ]   \n",
       "...                                                 ...   \n",
       "1794                         [let, go, usa, worldcup, ]   \n",
       "1795  [cheftomkerridg, comment, england, wale, game,...   \n",
       "1796  [welsh, passion, pride, fight, wowit, shame, t...   \n",
       "1797  [incred, see, ai, fail, predict, worldcup, win...   \n",
       "1798  [im, run, superl, ream, cb, hes, play, like, b...   \n",
       "\n",
       "                                             lemmatized sentiment_flair  \\\n",
       "0     [switchfoot, httptwitpiccom2y1zl, awww, thats,...        negative   \n",
       "1     [upset, cant, update, facebook, texting, might...        negative   \n",
       "2     [kenichan, dived, many, time, ball, managed, s...        positive   \n",
       "3              [whole, body, feel, itchy, like, fire, ]        negative   \n",
       "4     [nationwideclass, behaving, im, mad, cant, see, ]        negative   \n",
       "...                                                 ...             ...   \n",
       "1794                         [let, go, usa, worldcup, ]        positive   \n",
       "1795  [cheftomkerridge, commentating, england, wale,...        positive   \n",
       "1796  [welsh, passion, pride, fight, wowits, shame, ...        negative   \n",
       "1797  [incredible, see, ai, failing, predict, worldc...        negative   \n",
       "1798  [im, running, superlative, ream, cb, he, playi...        negative   \n",
       "\n",
       "     sentiment  confidence  \n",
       "0     NEGATIVE    0.996120  \n",
       "1     NEGATIVE    0.996055  \n",
       "2     POSITIVE    0.854769  \n",
       "3     NEGATIVE    0.985915  \n",
       "4     NEGATIVE    0.999555  \n",
       "...        ...         ...  \n",
       "1794  POSITIVE    0.978026  \n",
       "1795  POSITIVE    0.994031  \n",
       "1796  NEGATIVE    0.865182  \n",
       "1797  NEGATIVE    0.884833  \n",
       "1798  NEGATIVE    0.942696  \n",
       "\n",
       "[2042 rows x 11 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76774351-0ba2-4f50-9812-f58f5524ba8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.15.1-py2.py3-none-any.whl (10.3 MB)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\public\\miniconda3\\lib\\site-packages (from streamlit) (1.23.5)\n",
      "Collecting blinker>=1.0.0\n",
      "  Downloading blinker-1.5-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in c:\\users\\public\\miniconda3\\lib\\site-packages (from streamlit) (4.4.0)\n",
      "Collecting cachetools>=4.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\public\\miniconda3\\lib\\site-packages (from streamlit) (4.13.0)\n",
      "Collecting gitpython!=3.1.19\n",
      "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
      "Requirement already satisfied: pyarrow>=4.0 in c:\\users\\public\\miniconda3\\lib\\site-packages (from streamlit) (8.0.0)\n",
      "Collecting validators>=0.2\n",
      "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
      "Collecting watchdog\n",
      "  Downloading watchdog-2.1.9-py3-none-win_amd64.whl (78 kB)\n",
      "Requirement already satisfied: packaging>=14.1 in c:\\users\\public\\miniconda3\\lib\\site-packages (from streamlit) (21.3)\n",
      "Requirement already satisfied: tornado>=5.0 in c:\\users\\public\\miniconda3\\lib\\site-packages (from streamlit) (6.2)\n",
      "Collecting protobuf<4,>=3.12\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-win_amd64.whl (904 kB)\n",
      "Collecting altair>=3.2.0\n",
      "  Downloading altair-4.2.0-py3-none-any.whl (812 kB)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n",
      "Collecting semver\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: requests>=2.4 in c:\\users\\public\\miniconda3\\lib\\site-packages (from streamlit) (2.27.1)\n",
      "Collecting tzlocal>=1.1\n",
      "  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\public\\miniconda3\\lib\\site-packages (from streamlit) (9.3.0)\n",
      "Requirement already satisfied: pandas>=0.21.0 in c:\\users\\public\\miniconda3\\lib\\site-packages (from streamlit) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\public\\miniconda3\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\public\\miniconda3\\lib\\site-packages (from streamlit) (8.1.3)\n",
      "Collecting pympler>=0.9\n",
      "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "Collecting toolz\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\public\\miniconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (4.17.3)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\public\\miniconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\public\\miniconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\public\\miniconda3\\lib\\site-packages (from click>=7.0->streamlit) (0.4.4)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\public\\miniconda3\\lib\\site-packages (from importlib-metadata>=1.4->streamlit) (3.11.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\public\\miniconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\public\\miniconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.19.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\public\\miniconda3\\lib\\site-packages (from packaging>=14.1->streamlit) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\public\\miniconda3\\lib\\site-packages (from pandas>=0.21.0->streamlit) (2022.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\public\\miniconda3\\lib\\site-packages (from jinja2->altair>=3.2.0->streamlit) (2.1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\public\\miniconda3\\lib\\site-packages (from python-dateutil->streamlit) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\public\\miniconda3\\lib\\site-packages (from requests>=2.4->streamlit) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\public\\miniconda3\\lib\\site-packages (from requests>=2.4->streamlit) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\public\\miniconda3\\lib\\site-packages (from requests>=2.4->streamlit) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\public\\miniconda3\\lib\\site-packages (from requests>=2.4->streamlit) (1.26.8)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\public\\miniconda3\\lib\\site-packages (from rich>=10.11.0->streamlit) (2.13.0)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "Collecting tzdata\n",
      "  Downloading tzdata-2022.6-py2.py3-none-any.whl (338 kB)\n",
      "Collecting pytz-deprecation-shim\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\public\\miniconda3\\lib\\site-packages (from validators>=0.2->streamlit) (5.1.1)\n",
      "Building wheels for collected packages: validators\n",
      "  Building wheel for validators (setup.py): started\n",
      "  Building wheel for validators (setup.py): finished with status 'done'\n",
      "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=7ae14ab2de866c7949ad69c991d99fc9aef4d409189c9cde87cba4345b81d4d2\n",
      "  Stored in directory: c:\\users\\aulia asusk401l\\appdata\\local\\pip\\cache\\wheels\\2d\\f0\\a8\\1094fca7a7e5d0d12ff56e0c64675d72aa5cc81a5fc200e849\n",
      "Successfully built validators\n",
      "Installing collected packages: tzdata, smmap, toolz, pytz-deprecation-shim, gitdb, commonmark, watchdog, validators, tzlocal, toml, semver, rich, pympler, pydeck, protobuf, gitpython, cachetools, blinker, altair, streamlit\n",
      "Successfully installed altair-4.2.0 blinker-1.5 cachetools-5.2.0 commonmark-0.9.1 gitdb-4.0.10 gitpython-3.1.29 protobuf-3.20.3 pydeck-0.8.0 pympler-1.0.1 pytz-deprecation-shim-0.1.0.post0 rich-12.6.0 semver-2.13.0 smmap-5.0.0 streamlit-1.15.1 toml-0.10.2 toolz-0.12.0 tzdata-2022.6 tzlocal-4.2 validators-0.20.0 watchdog-2.1.9\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7296dbd3-927e-46a0-a401-65cff70dec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa6e40-24bd-4e19-b07f-6b01d9630716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_65907_row0_col1 {\n",
       "  background-color: #3f007d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_65907_row1_col1 {\n",
       "  background-color: #fcfbfd;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_65907\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_65907_level0_col0\" class=\"col_heading level0 col0\" >sentiment_flair</th>\n",
       "      <th id=\"T_65907_level0_col1\" class=\"col_heading level0 col1\" >twitcontent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_65907_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_65907_row0_col0\" class=\"data row0 col0\" >negative</td>\n",
       "      <td id=\"T_65907_row0_col1\" class=\"data row0 col1\" >1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_65907_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_65907_row1_col0\" class=\"data row1 col0\" >positive</td>\n",
       "      <td id=\"T_65907_row1_col1\" class=\"data row1 col1\" >894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22326063e20>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = data_file.groupby('sentiment_flair').count()['twitcontent'].reset_index().sort_values(by='twitcontent',ascending=False)\n",
    "temp.style.background_gradient(cmap='Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c48067dd-085e-4236-97eb-7d2b71632c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file.to_csv(r'data\\data_file.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f545d2c-fd93-41e7-8a15-b389a8ab8f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d984ebc-5146-4405-85e7-98a8d96eb735",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip --default-timeout=1200 install atoti[jupyterlab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6fe85ba-10d8-4223-a2bd-2ef761ee69ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to atoti 0.7.2!\n",
      "\n",
      "By using this community edition, you agree with the license available at https://docs.atoti.io/latest/eula.html.\n",
      "Browse the official documentation at https://docs.atoti.io.\n",
      "Join the community at https://www.atoti.io/register.\n",
      "\n",
      "atoti collects telemetry data, which is used to help understand how to improve the product.\n",
      "If you don't wish to send usage data, set the ATOTI_DISABLE_TELEMETRY environment variable to True.\n",
      "\n",
      "You can hide this message by setting the ATOTI_HIDE_EULA_MESSAGE environment variable to True.\n"
     ]
    }
   ],
   "source": [
    "import atoti as tt\n",
    "\n",
    "session = tt.Session(user_content_storage='./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3206f413-a88d-49bf-9195-efc80f7a043b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AtotiJavaException",
     "evalue": "LocalPath must be absolute.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAtotiJavaException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/data/data_file.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtwitid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\Public\\miniconda3\\lib\\site-packages\\atoti\\_telemetry\\track_calls.py:97\u001b[0m, in \u001b[0;36m_track_function_calls.<locals>.function_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m call_tracker\u001b[38;5;241m.\u001b[39mtracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _track_function_call(function, call_path, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     99\u001b[0m     call_tracker\u001b[38;5;241m.\u001b[39mtracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\Public\\miniconda3\\lib\\site-packages\\atoti\\_telemetry\\track_calls.py:59\u001b[0m, in \u001b[0;36m_track_function_call\u001b[1;34m(function, call_path, *args, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=bare-except\u001b[39;00m\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;66;03m# Do nothing to let the previous error be the one presented to the user.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     arguments: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mC:\\Users\\Public\\miniconda3\\lib\\site-packages\\atoti\\_telemetry\\track_calls.py:52\u001b[0m, in \u001b[0;36m_track_function_call\u001b[1;34m(function, call_path, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m call_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Users\\Public\\miniconda3\\lib\\site-packages\\atoti\\_runtime_type_checking_utils.py:177\u001b[0m, in \u001b[0;36m_TypecheckWrapperFactory.create_wrapper.<locals>.typechecked_func_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m typeguard\u001b[38;5;241m.\u001b[39mcheck_argument_types(memo)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m# Call the actual function.\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Users\\Public\\miniconda3\\lib\\site-packages\\atoti_core\\doc.py:21\u001b[0m, in \u001b[0;36mdoc.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Users\\Public\\miniconda3\\lib\\site-packages\\atoti\\session.py:638\u001b[0m, in \u001b[0;36mSession.read_csv\u001b[1;34m(self, path, keys, table_name, separator, encoding, process_quotes, partitioning, types, columns, array_separator, date_patterns, default_values, client_side_encryption)\u001b[0m\n\u001b[0;32m    632\u001b[0m path, pattern \u001b[38;5;241m=\u001b[39m split_path_and_pattern(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    634\u001b[0m table_name \u001b[38;5;241m=\u001b[39m _infer_table_name(\n\u001b[0;32m    635\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath, pattern\u001b[38;5;241m=\u001b[39mpattern, table_name\u001b[38;5;241m=\u001b[39mtable_name\n\u001b[0;32m    636\u001b[0m )\n\u001b[1;32m--> 638\u001b[0m csv_file_format \u001b[38;5;241m=\u001b[39m \u001b[43mCsvDataSource\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_data_into_table\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data_into_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscover_csv_file_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscover_csv_file_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscover_file_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocess_quotes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess_quotes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43marray_separator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marray_separator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpattern\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_patterns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_patterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mConstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdefault_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_side_encryption\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_side_encryption\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    657\u001b[0m types \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    658\u001b[0m     {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcsv_file_format\u001b[38;5;241m.\u001b[39mtypes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtypes}\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m csv_file_format\u001b[38;5;241m.\u001b[39mtypes\n\u001b[0;32m    661\u001b[0m )\n\u001b[0;32m    662\u001b[0m process_quotes \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    663\u001b[0m     process_quotes\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m process_quotes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m csv_file_format\u001b[38;5;241m.\u001b[39mprocess_quotes\n\u001b[0;32m    666\u001b[0m )\n",
      "File \u001b[1;32mC:\\Users\\Public\\miniconda3\\lib\\site-packages\\atoti\\_sources\\csv.py:103\u001b[0m, in \u001b[0;36mCsvDataSource.discover_file_format\u001b[1;34m(self, path, keys, separator, encoding, process_quotes, array_separator, pattern, date_patterns, default_values, client_side_encryption, columns)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m\"\"\"Infer Table types from a CSV file or directory.\"\"\"\u001b[39;00m\n\u001b[0;32m     92\u001b[0m source_params \u001b[38;5;241m=\u001b[39m create_csv_params(\n\u001b[0;32m     93\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m     94\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    101\u001b[0m     client_side_encryption\u001b[38;5;241m=\u001b[39mclient_side_encryption,\n\u001b[0;32m    102\u001b[0m )\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_discover_csv_file_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\Public\\miniconda3\\lib\\site-packages\\atoti\\_java_api.py:166\u001b[0m, in \u001b[0;36m_enhance_py4j_errors.<locals>.wrapped_method\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m java_exception:\n\u001b[0;32m    161\u001b[0m     cause \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28mstr\u001b[39m(java_exception)\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m get_env_flag(_VERBOSE_JAVA_EXCEPTIONS_ENV_VAR)\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_throwable_root_cause(java_exception\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    165\u001b[0m     )\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AtotiJavaException(\n\u001b[0;32m    167\u001b[0m         cause,\n\u001b[0;32m    168\u001b[0m         java_traceback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(java_exception),\n\u001b[0;32m    169\u001b[0m         java_exception\u001b[38;5;241m=\u001b[39mjava_exception,\n\u001b[0;32m    170\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mAtotiJavaException\u001b[0m: LocalPath must be absolute."
     ]
    }
   ],
   "source": [
    "table = session.read_csv(\"data/data/data_file.csv\", keys=[\"twitid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82b672-1e3c-4843-b788-205f6c0d3d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
